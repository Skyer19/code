{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d246dcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scgpt location:  /data/mr423/project/code/sexPrediction/scgpt/__init__.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'scgpt' from '/data/mr423/project/code/sexPrediction/scgpt/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# 检查 tempfile 模块使用的临时文件目录\n",
    "temp_dir = tempfile.gettempdir()\n",
    "print(\"Updated temp directory:\", temp_dir)\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# new_path = '../sexPrediction/'\n",
    "# if new_path not in sys.path:\n",
    "#     sys.path.insert(0, new_path)\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "# relaod the scgpt files\n",
    "import scgpt\n",
    "print(\"scgpt location: \", scgpt.__file__)\n",
    "importlib.reload(scgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb815e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 25 19:36:31 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   66C    P0             322W / 300W |   9698MiB / 81920MiB |     99%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1516      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A   1223977      C   python                                     9676MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3daceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "import pandas as pd\n",
    "# from . import asyn\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import wandb\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "import scgpt as scg\n",
    "\n",
    "from scgpt.model import TransformerModel\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt.utils import set_seed\n",
    "\n",
    "sc.set_figure_params(figsize=(6, 6))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ[\"WANDB_MODE\"]= \"offline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c090665",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Settings for wandb mentior\n",
    "######################################################################\n",
    "\n",
    "hyperparameter_defaults = dict(\n",
    "    seed=0,\n",
    "    do_train=True,\n",
    "    load_model=\"../../pre_trained_model/scGPT_human\",\n",
    "    n_bins=101,\n",
    "\n",
    "    epochs=2, # 2 !!!!!!!!!!!!  test only\n",
    "    lr=0.001,\n",
    "    batch_size=128,   # 128 !!!!!!!!!!!!  test only\n",
    "\n",
    "    layer_size=16, # 128\n",
    "    nlayers=4,  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    nhead=8,  # number of heads in nn.MultiheadAttention\n",
    "    \n",
    "    dropout=0.0,  # dropout probability\n",
    "\n",
    "    use_fast_transformer=True,\n",
    "    pre_norm=False,\n",
    "    amp=True,  # Automatic Mixed Precision\n",
    "    freeze = True, #freeze\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"gender_pred\",\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")\n",
    "config = wandb.config\n",
    "print(config)\n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Settings for input and preprocessing\n",
    "######################################################################\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_value = \"auto\"  # for masked values, now it should always be auto\n",
    "\n",
    "max_seq_len = 3001\n",
    "n_bins = config.n_bins\n",
    "\n",
    "# input/output representation\n",
    "input_style = \"binned\"  # \"normed_raw\", \"log1p\", or \"binned\"\n",
    "input_emb_style = \"category\"  # \"category\" or \"continuous\" or \"scaling\"\n",
    "cell_emb_style = \"cls\"  # \"avg-pool\" or \"w-pool\" or \"cls\"\n",
    "\n",
    "\n",
    "# settings for training\n",
    "CLS = True  # celltype classification objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Settings for optimizer\n",
    "######################################################################\n",
    "lr = config.lr\n",
    "batch_size = config.batch_size\n",
    "eval_batch_size = config.batch_size\n",
    "epochs = config.epochs\n",
    "early_stop = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Settings for the model\n",
    "######################################################################\n",
    "use_fast_transformer = config.use_fast_transformer\n",
    "fast_transformer_backend = \"flash\"  # \"linear\" or \"flash\"\n",
    "\n",
    "\n",
    "embsize = config.layer_size  # embedding dimension\n",
    "d_hid = config.layer_size  # dimension of the feedforward network in TransformerEncoder\n",
    "nlayers = config.nlayers  # number of TransformerEncoderLayer in TransformerEncoder\n",
    "nhead = config.nhead  # number of heads in nn.MultiheadAttention\n",
    "dropout = config.dropout  # dropout probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Validate the settings\n",
    "######################################################################\n",
    "# assert input_style in [\"normed_raw\", \"log1p\", \"binned\"]\n",
    "# assert output_style in [\"normed_raw\", \"log1p\", \"binned\"]\n",
    "\n",
    "assert input_emb_style in [\"category\", \"continuous\", \"scaling\"]\n",
    "if input_style == \"binned\":\n",
    "    if input_emb_style == \"scaling\":\n",
    "        raise ValueError(\"input_emb_style `scaling` is not supported for binned input.\")\n",
    "elif input_style == \"log1p\" or input_style == \"normed_raw\":\n",
    "    if input_emb_style == \"category\":\n",
    "        raise ValueError(\n",
    "            \"input_emb_style `category` is not supported for log1p or normed_raw input.\"\n",
    "        )\n",
    "\n",
    "if input_emb_style == \"category\":\n",
    "    mask_value = n_bins + 1\n",
    "    pad_value = n_bins  # for padding gene expr values\n",
    "    n_input_bins = n_bins + 2\n",
    "else:\n",
    "    mask_value = -1\n",
    "    pad_value = -2\n",
    "    n_input_bins = n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25227609",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Settings for the running recording\n",
    "######################################################################\n",
    "dataset_name = 'biobank-gender_pred'\n",
    "save_dir = Path(f\"./record/dev_{dataset_name}-{time.strftime('%b%d-%H-%M')}/\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"save to {save_dir}\")\n",
    "logger = scg.logger\n",
    "scg.utils.add_file_handler(logger, save_dir / \"run.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c7a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37304, 2919)\n",
      "(4145, 2919)\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Data loading\n",
    "######################################################################\n",
    "adata = sc.read(\"../../data/3-OLINK_data_train_withOutlier_all.h5ad\")\n",
    "adata_test = sc.read(\"../../data/3-OLINK_data_test_withOutlier_all.h5ad\")\n",
    "\n",
    "print(adata.shape)\n",
    "print(adata_test.shape)\n",
    "\n",
    "adata.obs[\"batch_id\"]  = adata.obs[\"str_batch\"] = \"0\"\n",
    "adata_test.obs[\"batch_id\"]  = adata_test.obs[\"str_batch\"] = \"1\" \n",
    "\n",
    "adata.var.set_index(adata.var[\"gene_name\"], inplace=True)\n",
    "adata_test.var.set_index(adata.var[\"gene_name\"], inplace=True)\n",
    "\n",
    "data_is_raw = False\n",
    "\n",
    "adata_test_raw = adata_test.copy()\n",
    "adata = adata.concatenate(adata_test, batch_key=\"str_batch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47134c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the batch category column\n",
    "batch_id_labels = adata.obs[\"str_batch\"].astype(\"category\").cat.codes.values\n",
    "adata.obs[\"batch_id\"] = batch_id_labels\n",
    "\n",
    "\n",
    "gender_id_labels = adata.obs[\"sex\"].astype(\"category\").cat.codes.values\n",
    "# ageGroup_types = adata.obs[\"Age_Group\"].unique()\n",
    "adata.obs[\"gender_id\"] = gender_id_labels\n",
    "\n",
    "\n",
    "n_cls = len(np.unique(gender_id_labels))\n",
    "\n",
    "id2type = dict(enumerate(adata.obs[\"sex\"].astype(\"category\").cat.categories))\n",
    "print(id2type)\n",
    "\n",
    "adata.var[\"gene_name\"] = adata.var.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8944aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# The pre-trained model\n",
    "######################################################################\n",
    "if config.load_model is not None:\n",
    "    model_dir = config.load_model\n",
    "    model_config_file = model_dir + \"/args.json\"\n",
    "    model_file = model_dir + \"/best_model.pt\"\n",
    "    vocab_file = model_dir + \"/vocab.json\"\n",
    "\n",
    "    vocab = GeneVocab.from_file(vocab_file)\n",
    "    shutil.copy(vocab_file, save_dir / \"vocab.json\")\n",
    "    for s in special_tokens:\n",
    "        if s not in vocab:\n",
    "            vocab.append_token(s)\n",
    "\n",
    "    adata.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in adata.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(adata.var[\"id_in_vocab\"])\n",
    "    logger.info(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    adata = adata[:, adata.var[\"id_in_vocab\"] >= 0]\n",
    "\n",
    "    # model\n",
    "    with open(model_config_file, \"r\") as f:\n",
    "        model_configs = json.load(f)\n",
    "    logger.info(\n",
    "        f\"Resume model from {model_file}, the model args will override the \"\n",
    "        f\"config {model_config_file}.\"\n",
    "    )\n",
    "    embsize = model_configs[\"embsize\"]\n",
    "    nhead = model_configs[\"nheads\"]\n",
    "    d_hid = model_configs[\"d_hid\"]\n",
    "    nlayers = model_configs[\"nlayers\"]\n",
    "    n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "\n",
    "    print(\"\\n**** parameters from the pre-trained model ****\")\n",
    "    print(f'layer_size = embsize: {model_configs[\"embsize\"]} = d_hid: {model_configs[\"d_hid\"]}, n_layers: {model_configs[\"nlayers\"]}, nhead: {model_configs[\"nheads\"]}')\n",
    "    print(\"**** parameters from the pre-trained model ****\\n\")\n",
    "\n",
    "    print(\"**** actual model parameters ****\")\n",
    "    print(f'layer_size = embsize: {embsize} = d_hid: {d_hid}, n_layers: {nlayers}, nhead: {nhead}')\n",
    "    print(\"**** actual model parameters ****\\n\")\n",
    "\n",
    "# set up the preprocessor, use the args to config the workflow\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=False,  # step 1\n",
    "    filter_cell_by_counts=False,  # step 2\n",
    "    normalize_total=3000,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=data_is_raw,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=False,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "\n",
    "\n",
    "adata_test = adata[adata.obs[\"str_batch\"] == \"1\"]\n",
    "adata = adata[adata.obs[\"str_batch\"] == \"0\"]\n",
    "\n",
    "preprocessor(adata, batch_key=None)\n",
    "preprocessor(adata_test, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Split the data to train and test\n",
    "######################################################################\n",
    "input_layer_key = {  # the values of this map coorespond to the keys in preprocessing\n",
    "    \"normed_raw\": \"X_normed\",\n",
    "    \"log1p\": \"X_normed\",\n",
    "    \"binned\": \"X_binned\",\n",
    "}[input_style]\n",
    "all_counts = (\n",
    "    adata.layers[input_layer_key].A\n",
    "    if issparse(adata.layers[input_layer_key])\n",
    "    else adata.layers[input_layer_key]\n",
    ")\n",
    "genes = adata.var[\"gene_name\"].tolist()\n",
    "\n",
    "gender_labels = adata.obs[\"gender_id\"].tolist()  # make sure count from 0\n",
    "gender_labels = np.array(gender_labels)\n",
    "\n",
    "\n",
    "(\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_gender,\n",
    "    valid_gender,\n",
    ") = train_test_split(\n",
    "    all_counts, gender_labels, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "if config.load_model is None:\n",
    "    vocab = Vocab(\n",
    "        VocabPybind(genes + special_tokens, None)\n",
    "    )  # bidirectional lookup [gene <-> int]\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "gene_ids = np.array(vocab(genes), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Tokenize the data\n",
    "######################################################################\n",
    "tokenized_train = tokenize_and_pad_batch(\n",
    "    train_data,\n",
    "    gene_ids,\n",
    "    max_len=max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,  # append <cls> token at the beginning\n",
    "    include_zero_gene=False,\n",
    ")\n",
    "tokenized_valid = tokenize_and_pad_batch(\n",
    "    valid_data,\n",
    "    gene_ids,\n",
    "    max_len=max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,\n",
    "    include_zero_gene=False,\n",
    ")\n",
    "logger.info(\n",
    "    f\"train set number of samples: {tokenized_train['genes'].shape[0]}, \"\n",
    "    f\"\\n\\t feature length: {tokenized_train['genes'].shape[1]}\"\n",
    ")\n",
    "logger.info(\n",
    "    f\"valid set number of samples: {tokenized_valid['genes'].shape[0]}, \"\n",
    "    f\"\\n\\t feature length: {tokenized_valid['genes'].shape[1]}\"\n",
    ")\n",
    "\n",
    "\n",
    "def prepare_data(sort_seq_batch=False) -> Tuple[Dict[str, torch.Tensor]]:\n",
    "    input_gene_ids_train, input_gene_ids_valid = (\n",
    "        tokenized_train[\"genes\"],\n",
    "        tokenized_valid[\"genes\"],\n",
    "    )\n",
    "\n",
    "    input_values_train, input_values_valid = (\n",
    "        tokenized_train[\"values\"],\n",
    "        tokenized_valid[\"values\"],\n",
    "    )\n",
    "\n",
    "    tensor_gender_train = torch.from_numpy(train_gender).long()\n",
    "    tensor_gender_valid = torch.from_numpy(valid_gender).long()\n",
    "\n",
    "\n",
    "    train_data_pt = {\n",
    "        \"gene_ids\": input_gene_ids_train,\n",
    "        \"values\": input_values_train,\n",
    "        \"gender\": tensor_gender_train,\n",
    "    }\n",
    "    valid_data_pt = {\n",
    "        \"gene_ids\": input_gene_ids_valid,\n",
    "        \"values\": input_values_valid,\n",
    "        \"gender\": tensor_gender_valid,\n",
    "    }\n",
    "\n",
    "    return train_data_pt, valid_data_pt\n",
    "\n",
    "\n",
    "# dataset\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data: Dict[str, torch.Tensor]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"gene_ids\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}\n",
    "\n",
    "\n",
    "# data_loader\n",
    "def prepare_dataloader(\n",
    "    data_pt: Dict[str, torch.Tensor],\n",
    "    batch_size: int,\n",
    "    shuffle: bool = False,\n",
    "    drop_last: bool = False,\n",
    "    num_workers: int = 0,\n",
    ") -> DataLoader:\n",
    "    if num_workers == 0:\n",
    "        num_workers = min(len(os.sched_getaffinity(0)), batch_size // 2)\n",
    "\n",
    "    dataset = SeqDataset(data_pt)\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ab9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Load the model\n",
    "######################################################################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    nlayers_cls=3,\n",
    "    n_cls=n_cls,\n",
    "    vocab=vocab,\n",
    "    dropout=dropout,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    do_mvc=False,\n",
    "    do_dab=False,\n",
    "    use_batch_labels=False,\n",
    "    num_batch_labels=False,\n",
    "    domain_spec_batchnorm=False,\n",
    "    input_emb_style=input_emb_style,\n",
    "    n_input_bins=n_input_bins,\n",
    "    cell_emb_style=cell_emb_style,\n",
    "    explicit_zero_prob=False,\n",
    "    use_fast_transformer=use_fast_transformer,\n",
    "    fast_transformer_backend=fast_transformer_backend,\n",
    "    pre_norm=config.pre_norm,\n",
    ")\n",
    "if config.load_model is not None:\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "        logger.info(f\"Loading ALL model params from {model_file}\")\n",
    "    except:\n",
    "        # only load params that are in the model and match the size\n",
    "        logger.info(f\"Loading SOME model params from {model_file}\")\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = torch.load(model_file)\n",
    "        pretrained_dict = {\n",
    "            k: v\n",
    "            for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape\n",
    "        }\n",
    "        # for k, v in pretrained_dict.items():\n",
    "        #     logger.info(f\"Loading params {k} with shape {v.shape}\")\n",
    "\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n",
    "pre_freeze_param_count = sum(dict((p.data_ptr(), p.numel()) for p in model.parameters() if p.requires_grad).values())\n",
    "\n",
    "# Freeze all pre-decoder weights\n",
    "for name, para in model.named_parameters():\n",
    "    # print(\"-\"*20)\n",
    "    print(f\"name: {name}\")\n",
    "\n",
    "    # if config.freeze and \"encoder\" in name and \"transformer_encoder\" not in name:\n",
    "    if config.freeze and \"encoder\" in name:\n",
    "        print(f\"freezing weights for: {name}\")\n",
    "        para.requires_grad = False\n",
    "\n",
    "post_freeze_param_count = sum(dict((p.data_ptr(), p.numel()) for p in model.parameters() if p.requires_grad).values())\n",
    "\n",
    "logger.info(f\"Total Pre freeze Params {(pre_freeze_param_count )}\")\n",
    "logger.info(f\"Total Post freeze Params {(post_freeze_param_count )}\")\n",
    "\n",
    "wandb.log(\n",
    "        {\n",
    "            \"info/pre_freeze_param_count\": pre_freeze_param_count,\n",
    "            \"info/post_freeze_param_count\": post_freeze_param_count,\n",
    "        },\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(model)\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace277c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Loss function\n",
    "######################################################################\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     model.parameters(), lr=lr, eps=1e-4)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1, gamma=0.9)\n",
    "# scaler = torch.cuda.amp.GradScaler(enabled=config.amp)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f20fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Train the model\n",
    "######################################################################\n",
    "def train(model: nn.Module, loader: DataLoader) -> None:\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_num = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "\n",
    "    for batch, batch_data in enumerate(loader):\n",
    "        input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "        input_values = batch_data[\"values\"].to(device)\n",
    "        gender = batch_data[\"gender\"].to(device)\n",
    "\n",
    "        src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "        with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "            output_dict = model(\n",
    "                input_gene_ids,\n",
    "                input_values,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_labels=None,\n",
    "                CLS=CLS,\n",
    "                CCE=False,\n",
    "                MVC=False,\n",
    "                ECS=False,\n",
    "                do_sample=False,\n",
    "                #generative_training=False\n",
    "            )\n",
    "\n",
    "            loss = 0.0\n",
    "            loss = criterion_cls(output_dict[\"classified_output\"], gender)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * len(input_gene_ids)\n",
    "        total_num += len(input_gene_ids)\n",
    "\n",
    "        preds = output_dict[\"classified_output\"].argmax(dim=1).cpu().numpy()\n",
    "        labels = gender.cpu().numpy()\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    epoch_loss = total_loss / total_num\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "\n",
    "    logger.info(\"-\" * 89)\n",
    "    logger.info(f\"Epoch {epoch}/{epochs}\")\n",
    "    logger.info(\n",
    "    f\"| train | total_num {total_num} | epoch loss {epoch_loss:5.4f} | precision {precision:5.4f} | \" \n",
    "    f\" recall {recall:5.4f} | f1 {f1:5.4f} |\" \n",
    "    f\" accuracy {accuracy:5.4f}\")\n",
    "\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"train/loss\": epoch_loss,\n",
    "            \"train/precision\": precision,\n",
    "            \"train/recall\": recall,\n",
    "            \"train/f1\": f1,\n",
    "            \"train/accuracy\": accuracy,\n",
    "            \"epoch\": epoch,\n",
    "        },\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11def3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Evaluate the model\n",
    "######################################################################\n",
    "def evaluate(model: nn.Module, loader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the evaluation data.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_num = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in loader:\n",
    "            input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "            input_values = batch_data[\"values\"].to(device)\n",
    "            gender = batch_data[\"gender\"].to(device)\n",
    "\n",
    "            src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "                output_dict = model(\n",
    "                    input_gene_ids,\n",
    "                    input_values,\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    batch_labels=None,\n",
    "                    CLS=CLS,  # evaluation does not need CLS or CCE\n",
    "                    CCE=False,\n",
    "                    MVC=False,\n",
    "                    ECS=False,\n",
    "                    do_sample=False,\n",
    "                    #generative_training = False,\n",
    "                )\n",
    "\n",
    "                loss = criterion_cls(output_dict[\"classified_output\"], gender)\n",
    "            \n",
    "            total_loss += loss.item() * len(input_gene_ids)\n",
    "            total_num += len(input_gene_ids)\n",
    "            \n",
    "            preds = output_dict[\"classified_output\"].argmax(dim=1).cpu().numpy()\n",
    "            labels = gender.cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "\n",
    "    # 定义评估指标函数\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    val_loss = total_loss / total_num\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "     \n",
    "    wandb.log(\n",
    "        {\n",
    "            \"valid/loss\": val_loss,\n",
    "            \"valid/precision\": precision,\n",
    "            \"valid/recall\": recall,\n",
    "            \"valid/f1\": f1,\n",
    "            \"valid/accuracy\": accuracy,\n",
    "            \"epoch\": epoch,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    logger.info(\n",
    "    f\"| valid | total_num {total_num} | epoch loss {val_loss:5.4f} | precision {precision:5.4f} | \" \n",
    "    f\" recall {recall:5.4f} | f1 {f1:5.4f} | \" \n",
    "    f\" accuracy {accuracy:5.4f}\")\n",
    "    logger.info(\"-\" * 89)\n",
    "\n",
    "\n",
    "    return val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410999e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# 训练和验证循环\n",
    "######################################################################\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_avg_bio = 0.0\n",
    "best_model = None\n",
    "\n",
    "logger.info(\"Apply the model on the age of the clusters \\n\")\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    train_data_pt, valid_data_pt = prepare_data()\n",
    "    train_loader = prepare_dataloader(\n",
    "        train_data_pt,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    valid_loader = prepare_dataloader(\n",
    "        valid_data_pt,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    if config.do_train:\n",
    "        train(model,loader=train_loader,)\n",
    "   \n",
    "    val_loss = evaluate(model,loader=valid_loader)\n",
    "\n",
    "    # early stop\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        logger.info(f\"Best model with score {best_val_loss:5.4f}\")\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= early_stop:\n",
    "            logger.info(f\"Early stop at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "\n",
    "# save the model into the save_dir\n",
    "torch.save(best_model.state_dict(), save_dir / \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Test the model\n",
    "######################################################################\n",
    "def test(model: nn.Module, adata: DataLoader):\n",
    "    \n",
    "    all_counts = (\n",
    "        adata.layers[input_layer_key].A\n",
    "        if issparse(adata.layers[input_layer_key])\n",
    "        else adata.layers[input_layer_key]\n",
    "    )\n",
    "\n",
    "    # print(adata.layers[input_layer_key])\n",
    "\n",
    "    gender_labels = adata.obs[\"gender_id\"].tolist()\n",
    "    gender_labels = np.array(gender_labels)\n",
    "\n",
    "\n",
    "    tokenized_test = tokenize_and_pad_batch(\n",
    "        all_counts,\n",
    "        gene_ids,\n",
    "        max_len=max_seq_len,\n",
    "        vocab=vocab,\n",
    "        pad_token=pad_token,\n",
    "        pad_value=pad_value,\n",
    "        append_cls=True,  # append <cls> token at the beginning\n",
    "        include_zero_gene=False,\n",
    "    )\n",
    "\n",
    "    tensor_gender_test = torch.from_numpy(gender_labels).long()\n",
    "\n",
    "\n",
    "    test_data_pt = {\n",
    "        \"gene_ids\": tokenized_test[\"genes\"],\n",
    "        \"values\": tokenized_test[\"values\"],\n",
    "        \"gender\": tensor_gender_test,\n",
    "    }\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        dataset=SeqDataset(test_data_pt),\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=min(len(os.sched_getaffinity(0)), eval_batch_size // 2),\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_num = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "            input_values = batch_data[\"values\"].to(device)\n",
    "            gender = batch_data[\"gender\"].to(device)\n",
    "\n",
    "            src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "            with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "                output_dict = model(\n",
    "                    input_gene_ids,\n",
    "                    input_values,\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    batch_labels=None,\n",
    "                    CLS=True, \n",
    "                    CCE=False,\n",
    "                    MVC=False,\n",
    "                    ECS=False,\n",
    "                    do_sample=False,\n",
    "                    #generative_training = False,\n",
    "                )\n",
    "                    \n",
    "                loss = criterion_cls(output_dict[\"classified_output\"], gender)\n",
    "            \n",
    "            total_loss += loss.item() * len(input_gene_ids)\n",
    "            total_num += len(input_gene_ids)\n",
    "                   \n",
    "            preds = output_dict[\"classified_output\"].argmax(dim=1).cpu().numpy()\n",
    "            labels = gender.cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "   \n",
    "    logger.info(\"-\" * 89)\n",
    "    logger.info(\"-\" * 89)\n",
    "    \n",
    "    logger.info(\n",
    "    f\"| test | total_num {total_num} | precision {precision:5.4f} | \" \n",
    "    f\" recall {recall:5.4f} | f1 {f1:5.4f} | \" \n",
    "    f\" accuracy {accuracy:5.4f}\")\n",
    "    logger.info(\"-\" * 89)    \n",
    "    \n",
    "    \n",
    "\n",
    "    # 保存数据到 CSV 文件\n",
    "    all_preds_list = all_preds.tolist()\n",
    "    all_labels_list = all_labels.tolist()\n",
    "\n",
    "    all_preds_save_dir = str(save_dir) + \"/all_preds.txt\"\n",
    "    all_labels_save_dir = str(save_dir) + \"/all_targets.txt\"\n",
    "\n",
    "    with open(all_preds_save_dir, \"w\") as file:\n",
    "        file.write(str(all_preds_list))\n",
    "\n",
    "    with open(all_labels_save_dir, \"w\") as file:\n",
    "        file.write(str(all_labels_list))\n",
    "\n",
    "    all_preds_df = pd.DataFrame(all_preds_list, columns=['Predictions'])\n",
    "    all_labels_df = pd.DataFrame(all_labels_list, columns=['Target'])\n",
    "\n",
    "    combined_df = pd.concat([all_preds_df, all_labels_df], axis=1)\n",
    "    combined_df['Predictions'] = combined_df['Predictions'].round(1)\n",
    "    combined_df['Target'] = combined_df['Target'].round(1)\n",
    "\n",
    "    combined_df.to_csv(str(save_dir) + \"/output.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc792dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "test(model, adata_test)\n",
    "\n",
    "# %%\n",
    "\n",
    "df = pd.read_csv(str(save_dir) + \"/output.csv\")\n",
    "\n",
    "y_true = df['Target']\n",
    "y_pred = df['Predictions']\n",
    "\n",
    "\n",
    "# 定义评估指标函数\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# 输出结果\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {f1}')\n",
    "print(f'accuracy: {accuracy:.2f}')\n",
    "print(f'conf_matrix: {conf_matrix}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ecc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存 ROC 曲线和 PR 曲线图像\n",
    "# from sklearn.metrics import roc_auc_score, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 计算 AUC-ROC\n",
    "# roc_auc = roc_auc_score(y_true, y_pred_prob)\n",
    "# fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
    "\n",
    "# # 绘制并保存 ROC 曲线\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.savefig('roc_curve.png')  # 保存图片\n",
    "# plt.close()  # 关闭绘图窗口\n",
    "\n",
    "# print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# # 计算 AUC-PR\n",
    "# precision_vals, recall_vals, _ = precision_recall_curve(y_true, y_pred_prob)\n",
    "# pr_auc = auc(recall_vals, precision_vals)\n",
    "\n",
    "# # 绘制并保存 PR 曲线\n",
    "# plt.figure()\n",
    "# plt.plot(recall_vals, precision_vals, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.title('Precision-Recall Curve')\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig('pr_curve.png')  # 保存图片\n",
    "# plt.close()  # 关闭绘图窗口\n",
    "\n",
    "# print(f\"AUC-PR: {pr_auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521338d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
